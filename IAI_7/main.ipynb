{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def generate_dataset(size=10000, length=15, pattern=\"aabbb\"):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    half_size = size // 2\n",
    "    \n",
    "    # Generate strings that CONTAIN the pattern\n",
    "    while len(dataset) < half_size:\n",
    "        s = \"\".join(random.choice(\"abcd\") for _ in range(length))\n",
    "        if pattern in s:\n",
    "            dataset.append(s)\n",
    "            labels.append(1)\n",
    "    \n",
    "    # Generate strings that DO NOT CONTAIN the pattern\n",
    "    while len(dataset) < size:\n",
    "        s = \"\".join(random.choice(\"abcd\") for _ in range(length))\n",
    "        if pattern not in s:\n",
    "            dataset.append(s)\n",
    "            labels.append(0)\n",
    "    \n",
    "    return dataset, labels\n",
    "\n",
    "def encode_strings(strings):\n",
    "    char_map = {'a': 0, 'b': 1, 'c': 2, 'd': 3}\n",
    "    X = []\n",
    "    for s in strings:\n",
    "        arr = np.zeros((len(s), 4), dtype=np.float32)\n",
    "        for i, ch in enumerate(s):\n",
    "            arr[i, char_map[ch]] = 1.0\n",
    "        X.append(arr)\n",
    "    return np.array(X, dtype=np.float32)\n",
    "\n",
    "dataset, labels = generate_dataset()\n",
    "combined = list(zip(dataset, labels))\n",
    "random.shuffle(combined)\n",
    "\n",
    "train_size = 7000\n",
    "train_data = combined[:train_size]\n",
    "test_data = combined[train_size:]\n",
    "\n",
    "X_train = encode_strings([t[0] for t in train_data])\n",
    "y_train = np.array([t[1] for t in train_data], dtype=np.float32)\n",
    "X_test = encode_strings([t[0] for t in test_data])\n",
    "y_test = np.array([t[1] for t in test_data], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/.venv_3_12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5052 - loss: 0.7180 - val_accuracy: 0.5243 - val_loss: 0.7008\n",
      "Epoch 2/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.5286 - loss: 0.6962 - val_accuracy: 0.5270 - val_loss: 0.6928\n",
      "Epoch 3/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.5580 - loss: 0.6865 - val_accuracy: 0.5533 - val_loss: 0.6820\n",
      "Epoch 4/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.5664 - loss: 0.6762 - val_accuracy: 0.5870 - val_loss: 0.6604\n",
      "Epoch 5/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.6198 - loss: 0.6462 - val_accuracy: 0.6383 - val_loss: 0.6307\n",
      "Epoch 6/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.6815 - loss: 0.6153 - val_accuracy: 0.6933 - val_loss: 0.5971\n",
      "Epoch 7/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.7320 - loss: 0.5832 - val_accuracy: 0.7370 - val_loss: 0.5664\n",
      "Epoch 8/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.7732 - loss: 0.5466 - val_accuracy: 0.7783 - val_loss: 0.5376\n",
      "Epoch 9/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.7988 - loss: 0.5208 - val_accuracy: 0.8113 - val_loss: 0.5091\n",
      "Epoch 10/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8264 - loss: 0.4957 - val_accuracy: 0.8270 - val_loss: 0.4825\n",
      "Epoch 11/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.8310 - loss: 0.4737 - val_accuracy: 0.8333 - val_loss: 0.4587\n",
      "Epoch 12/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8504 - loss: 0.4465 - val_accuracy: 0.8470 - val_loss: 0.4368\n",
      "Epoch 13/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8618 - loss: 0.4301 - val_accuracy: 0.8620 - val_loss: 0.4184\n",
      "Epoch 14/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8775 - loss: 0.4083 - val_accuracy: 0.8737 - val_loss: 0.4020\n",
      "Epoch 15/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8798 - loss: 0.3947 - val_accuracy: 0.8783 - val_loss: 0.3874\n",
      "Epoch 16/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8858 - loss: 0.3769 - val_accuracy: 0.8730 - val_loss: 0.3757\n",
      "Epoch 17/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.8818 - loss: 0.3623 - val_accuracy: 0.8853 - val_loss: 0.3648\n",
      "Epoch 18/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.8860 - loss: 0.3620 - val_accuracy: 0.8827 - val_loss: 0.3562\n",
      "Epoch 19/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.8884 - loss: 0.3582 - val_accuracy: 0.8840 - val_loss: 0.3487\n",
      "Epoch 20/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8987 - loss: 0.3503 - val_accuracy: 0.8910 - val_loss: 0.3419\n",
      "Epoch 21/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9025 - loss: 0.3360 - val_accuracy: 0.9037 - val_loss: 0.3359\n",
      "Epoch 22/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9125 - loss: 0.3215 - val_accuracy: 0.9087 - val_loss: 0.3303\n",
      "Epoch 23/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9143 - loss: 0.3218 - val_accuracy: 0.9120 - val_loss: 0.3253\n",
      "Epoch 24/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9189 - loss: 0.3212 - val_accuracy: 0.9133 - val_loss: 0.3208\n",
      "Epoch 25/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9180 - loss: 0.3212 - val_accuracy: 0.9147 - val_loss: 0.3166\n",
      "Epoch 26/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9177 - loss: 0.3184 - val_accuracy: 0.9177 - val_loss: 0.3127\n",
      "Epoch 27/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9233 - loss: 0.3093 - val_accuracy: 0.9163 - val_loss: 0.3096\n",
      "Epoch 28/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9238 - loss: 0.3050 - val_accuracy: 0.9180 - val_loss: 0.3059\n",
      "Epoch 29/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9290 - loss: 0.2891 - val_accuracy: 0.9200 - val_loss: 0.3030\n",
      "Epoch 30/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9264 - loss: 0.3037 - val_accuracy: 0.9200 - val_loss: 0.3002\n",
      "Epoch 31/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9280 - loss: 0.2946 - val_accuracy: 0.9200 - val_loss: 0.2977\n",
      "Epoch 32/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9329 - loss: 0.2831 - val_accuracy: 0.9210 - val_loss: 0.2956\n",
      "Epoch 33/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9270 - loss: 0.2947 - val_accuracy: 0.9210 - val_loss: 0.2934\n",
      "Epoch 34/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9327 - loss: 0.2845 - val_accuracy: 0.9210 - val_loss: 0.2915\n",
      "Epoch 35/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9314 - loss: 0.2788 - val_accuracy: 0.9210 - val_loss: 0.2897\n",
      "Epoch 36/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9260 - loss: 0.2868 - val_accuracy: 0.9220 - val_loss: 0.2881\n",
      "Epoch 37/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9277 - loss: 0.2863 - val_accuracy: 0.9220 - val_loss: 0.2867\n",
      "Epoch 38/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9327 - loss: 0.2751 - val_accuracy: 0.9220 - val_loss: 0.2852\n",
      "Epoch 39/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9301 - loss: 0.2792 - val_accuracy: 0.9220 - val_loss: 0.2839\n",
      "Epoch 40/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9316 - loss: 0.2751 - val_accuracy: 0.9220 - val_loss: 0.2828\n",
      "Epoch 41/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9294 - loss: 0.2750 - val_accuracy: 0.9223 - val_loss: 0.2817\n",
      "Epoch 42/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9297 - loss: 0.2785 - val_accuracy: 0.9223 - val_loss: 0.2807\n",
      "Epoch 43/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9326 - loss: 0.2725 - val_accuracy: 0.9223 - val_loss: 0.2797\n",
      "Epoch 44/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9355 - loss: 0.2559 - val_accuracy: 0.9223 - val_loss: 0.2790\n",
      "Epoch 45/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9351 - loss: 0.2615 - val_accuracy: 0.9223 - val_loss: 0.2779\n",
      "Epoch 46/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9290 - loss: 0.2740 - val_accuracy: 0.9223 - val_loss: 0.2770\n",
      "Epoch 47/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9335 - loss: 0.2626 - val_accuracy: 0.9230 - val_loss: 0.2765\n",
      "Epoch 48/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9306 - loss: 0.2636 - val_accuracy: 0.9230 - val_loss: 0.2754\n",
      "Epoch 49/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9329 - loss: 0.2606 - val_accuracy: 0.9230 - val_loss: 0.2747\n",
      "Epoch 50/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9243 - loss: 0.2866 - val_accuracy: 0.9227 - val_loss: 0.2739\n",
      "Epoch 51/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9373 - loss: 0.2573 - val_accuracy: 0.9233 - val_loss: 0.2733\n",
      "Epoch 52/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9299 - loss: 0.2642 - val_accuracy: 0.9230 - val_loss: 0.2724\n",
      "Epoch 53/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9336 - loss: 0.2560 - val_accuracy: 0.9233 - val_loss: 0.2713\n",
      "Epoch 54/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9289 - loss: 0.2713 - val_accuracy: 0.9233 - val_loss: 0.2695\n",
      "Epoch 55/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9379 - loss: 0.2484 - val_accuracy: 0.9237 - val_loss: 0.2682\n",
      "Epoch 56/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.9311 - loss: 0.2595 - val_accuracy: 0.9237 - val_loss: 0.2667\n",
      "Epoch 57/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.9336 - loss: 0.2516 - val_accuracy: 0.9237 - val_loss: 0.2653\n",
      "Epoch 58/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9379 - loss: 0.2451 - val_accuracy: 0.9237 - val_loss: 0.2636\n",
      "Epoch 59/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9309 - loss: 0.2509 - val_accuracy: 0.9237 - val_loss: 0.2604\n",
      "Epoch 60/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 0.9348 - loss: 0.2478 - val_accuracy: 0.9243 - val_loss: 0.2574\n",
      "Epoch 61/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9351 - loss: 0.2439 - val_accuracy: 0.9243 - val_loss: 0.2544\n",
      "Epoch 62/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9323 - loss: 0.2465 - val_accuracy: 0.9243 - val_loss: 0.2516\n",
      "Epoch 63/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9327 - loss: 0.2440 - val_accuracy: 0.9250 - val_loss: 0.2492\n",
      "Epoch 64/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9347 - loss: 0.2347 - val_accuracy: 0.9250 - val_loss: 0.2470\n",
      "Epoch 65/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9316 - loss: 0.2452 - val_accuracy: 0.9293 - val_loss: 0.2450\n",
      "Epoch 66/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 0.9363 - loss: 0.2310 - val_accuracy: 0.9317 - val_loss: 0.2432\n",
      "Epoch 67/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9360 - loss: 0.2356 - val_accuracy: 0.9323 - val_loss: 0.2413\n",
      "Epoch 68/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9402 - loss: 0.2246 - val_accuracy: 0.9333 - val_loss: 0.2399\n",
      "Epoch 69/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9389 - loss: 0.2292 - val_accuracy: 0.9333 - val_loss: 0.2387\n",
      "Epoch 70/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9413 - loss: 0.2203 - val_accuracy: 0.9333 - val_loss: 0.2376\n",
      "Epoch 71/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9320 - loss: 0.2432 - val_accuracy: 0.9337 - val_loss: 0.2365\n",
      "Epoch 72/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9413 - loss: 0.2223 - val_accuracy: 0.9347 - val_loss: 0.2357\n",
      "Epoch 73/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9419 - loss: 0.2205 - val_accuracy: 0.9353 - val_loss: 0.2349\n",
      "Epoch 74/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.9461 - loss: 0.2103 - val_accuracy: 0.9353 - val_loss: 0.2343\n",
      "Epoch 75/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9413 - loss: 0.2233 - val_accuracy: 0.9357 - val_loss: 0.2338\n",
      "Epoch 76/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9416 - loss: 0.2214 - val_accuracy: 0.9357 - val_loss: 0.2332\n",
      "Epoch 77/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9406 - loss: 0.2241 - val_accuracy: 0.9357 - val_loss: 0.2328\n",
      "Epoch 78/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9438 - loss: 0.2122 - val_accuracy: 0.9357 - val_loss: 0.2325\n",
      "Epoch 79/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9428 - loss: 0.2174 - val_accuracy: 0.9357 - val_loss: 0.2322\n",
      "Epoch 80/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9441 - loss: 0.2114 - val_accuracy: 0.9357 - val_loss: 0.2320\n",
      "Epoch 81/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9445 - loss: 0.2113 - val_accuracy: 0.9357 - val_loss: 0.2317\n",
      "Epoch 82/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9429 - loss: 0.2161 - val_accuracy: 0.9357 - val_loss: 0.2316\n",
      "Epoch 83/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9411 - loss: 0.2204 - val_accuracy: 0.9357 - val_loss: 0.2314\n",
      "Epoch 84/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9431 - loss: 0.2149 - val_accuracy: 0.9357 - val_loss: 0.2313\n",
      "Epoch 85/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9438 - loss: 0.2119 - val_accuracy: 0.9357 - val_loss: 0.2313\n",
      "Epoch 86/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9464 - loss: 0.2092 - val_accuracy: 0.9357 - val_loss: 0.2311\n",
      "Epoch 87/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9463 - loss: 0.2071 - val_accuracy: 0.9357 - val_loss: 0.2310\n",
      "Epoch 88/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9467 - loss: 0.2027 - val_accuracy: 0.9357 - val_loss: 0.2310\n",
      "Epoch 89/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.9477 - loss: 0.2016 - val_accuracy: 0.9357 - val_loss: 0.2309\n",
      "Epoch 90/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9435 - loss: 0.2117 - val_accuracy: 0.9357 - val_loss: 0.2309\n",
      "Epoch 91/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9422 - loss: 0.2139 - val_accuracy: 0.9357 - val_loss: 0.2308\n",
      "Epoch 92/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9449 - loss: 0.2091 - val_accuracy: 0.9357 - val_loss: 0.2308\n",
      "Epoch 93/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9491 - loss: 0.1972 - val_accuracy: 0.9357 - val_loss: 0.2307\n",
      "Epoch 94/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9434 - loss: 0.2089 - val_accuracy: 0.9357 - val_loss: 0.2308\n",
      "Epoch 95/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9437 - loss: 0.2123 - val_accuracy: 0.9357 - val_loss: 0.2307\n",
      "Epoch 96/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9447 - loss: 0.2105 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 97/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9391 - loss: 0.2238 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 98/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9428 - loss: 0.2156 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 99/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9419 - loss: 0.2155 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 100/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9424 - loss: 0.2134 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 101/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9447 - loss: 0.2102 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 102/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9352 - loss: 0.2324 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 103/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9451 - loss: 0.2092 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 104/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9463 - loss: 0.2034 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 105/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9474 - loss: 0.2007 - val_accuracy: 0.9357 - val_loss: 0.2306\n",
      "Epoch 106/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9445 - loss: 0.2094 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 107/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9452 - loss: 0.2046 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 108/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9477 - loss: 0.2002 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 109/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9469 - loss: 0.2023 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 110/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9435 - loss: 0.2107 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 111/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9391 - loss: 0.2231 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 112/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9403 - loss: 0.2210 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 113/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9453 - loss: 0.2097 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 114/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9427 - loss: 0.2129 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 115/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9444 - loss: 0.2082 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 116/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9391 - loss: 0.2251 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 117/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9430 - loss: 0.2130 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 118/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9368 - loss: 0.2276 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 119/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9505 - loss: 0.1910 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 120/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9402 - loss: 0.2199 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 121/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9433 - loss: 0.2127 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 122/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9428 - loss: 0.2121 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 123/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9425 - loss: 0.2131 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 124/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9424 - loss: 0.2132 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 125/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.9444 - loss: 0.2069 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 126/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9462 - loss: 0.2057 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 127/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9422 - loss: 0.2138 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 128/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9403 - loss: 0.2197 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 129/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9463 - loss: 0.2023 - val_accuracy: 0.9357 - val_loss: 0.2305\n",
      "Epoch 130/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9433 - loss: 0.2127 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 131/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9407 - loss: 0.2208 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 132/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9462 - loss: 0.2041 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 133/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9434 - loss: 0.2108 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 134/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9422 - loss: 0.2151 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 135/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9437 - loss: 0.2122 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 136/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9442 - loss: 0.2087 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 137/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9427 - loss: 0.2131 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 138/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9463 - loss: 0.2041 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 139/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9495 - loss: 0.1947 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 140/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9437 - loss: 0.2122 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 141/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9387 - loss: 0.2254 - val_accuracy: 0.9357 - val_loss: 0.2304\n",
      "Epoch 142/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9474 - loss: 0.1983 - val_accuracy: 0.9357 - val_loss: 0.1825\n",
      "Epoch 143/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9456 - loss: 0.1538 - val_accuracy: 0.9377 - val_loss: 0.1375\n",
      "Epoch 144/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9559 - loss: 0.1340 - val_accuracy: 0.9857 - val_loss: 0.1153\n",
      "Epoch 145/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9866 - loss: 0.1043 - val_accuracy: 0.9857 - val_loss: 0.0997\n",
      "Epoch 146/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9846 - loss: 0.0958 - val_accuracy: 0.9857 - val_loss: 0.0875\n",
      "Epoch 147/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9860 - loss: 0.0805 - val_accuracy: 0.9857 - val_loss: 0.0781\n",
      "Epoch 148/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9863 - loss: 0.0730 - val_accuracy: 0.9857 - val_loss: 0.0706\n",
      "Epoch 149/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9853 - loss: 0.0690 - val_accuracy: 0.9857 - val_loss: 0.0643\n",
      "Epoch 150/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9852 - loss: 0.0612 - val_accuracy: 0.9857 - val_loss: 0.0591\n",
      "Epoch 151/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9866 - loss: 0.0572 - val_accuracy: 0.9857 - val_loss: 0.0548\n",
      "Epoch 152/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9854 - loss: 0.0539 - val_accuracy: 0.9857 - val_loss: 0.0511\n",
      "Epoch 153/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9859 - loss: 0.0558 - val_accuracy: 0.9883 - val_loss: 0.0478\n",
      "Epoch 154/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9901 - loss: 0.0442 - val_accuracy: 0.9903 - val_loss: 0.0450\n",
      "Epoch 155/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9923 - loss: 0.0427 - val_accuracy: 0.9930 - val_loss: 0.0425\n",
      "Epoch 156/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9930 - loss: 0.0451 - val_accuracy: 0.9950 - val_loss: 0.0403\n",
      "Epoch 157/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9938 - loss: 0.0419 - val_accuracy: 0.9950 - val_loss: 0.0383\n",
      "Epoch 158/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9943 - loss: 0.0375 - val_accuracy: 0.9950 - val_loss: 0.0366\n",
      "Epoch 159/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9958 - loss: 0.0316 - val_accuracy: 0.9950 - val_loss: 0.0350\n",
      "Epoch 160/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9941 - loss: 0.0349 - val_accuracy: 0.9943 - val_loss: 0.0335\n",
      "Epoch 161/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9940 - loss: 0.0304 - val_accuracy: 0.9943 - val_loss: 0.0321\n",
      "Epoch 162/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9937 - loss: 0.0317 - val_accuracy: 0.9950 - val_loss: 0.0309\n",
      "Epoch 163/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9937 - loss: 0.0302 - val_accuracy: 0.9950 - val_loss: 0.0298\n",
      "Epoch 164/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9943 - loss: 0.0311 - val_accuracy: 0.9963 - val_loss: 0.0287\n",
      "Epoch 165/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9962 - loss: 0.0257 - val_accuracy: 0.9963 - val_loss: 0.0277\n",
      "Epoch 166/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9968 - loss: 0.0254 - val_accuracy: 0.9963 - val_loss: 0.0268\n",
      "Epoch 167/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9974 - loss: 0.0224 - val_accuracy: 0.9963 - val_loss: 0.0260\n",
      "Epoch 168/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9949 - loss: 0.0263 - val_accuracy: 0.9963 - val_loss: 0.0252\n",
      "Epoch 169/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9964 - loss: 0.0227 - val_accuracy: 0.9963 - val_loss: 0.0244\n",
      "Epoch 170/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9962 - loss: 0.0220 - val_accuracy: 0.9963 - val_loss: 0.0237\n",
      "Epoch 171/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9956 - loss: 0.0225 - val_accuracy: 0.9963 - val_loss: 0.0231\n",
      "Epoch 172/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9970 - loss: 0.0198 - val_accuracy: 0.9963 - val_loss: 0.0225\n",
      "Epoch 173/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9956 - loss: 0.0218 - val_accuracy: 0.9963 - val_loss: 0.0219\n",
      "Epoch 174/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9971 - loss: 0.0178 - val_accuracy: 0.9963 - val_loss: 0.0215\n",
      "Epoch 175/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9964 - loss: 0.0195 - val_accuracy: 0.9963 - val_loss: 0.0210\n",
      "Epoch 176/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9963 - loss: 0.0192 - val_accuracy: 0.9963 - val_loss: 0.0205\n",
      "Epoch 177/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9956 - loss: 0.0214 - val_accuracy: 0.9963 - val_loss: 0.0201\n",
      "Epoch 178/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9969 - loss: 0.0184 - val_accuracy: 0.9963 - val_loss: 0.0197\n",
      "Epoch 179/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9968 - loss: 0.0162 - val_accuracy: 0.9963 - val_loss: 0.0193\n",
      "Epoch 180/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9966 - loss: 0.0171 - val_accuracy: 0.9963 - val_loss: 0.0190\n",
      "Epoch 181/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9969 - loss: 0.0158 - val_accuracy: 0.9963 - val_loss: 0.0186\n",
      "Epoch 182/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9972 - loss: 0.0154 - val_accuracy: 0.9963 - val_loss: 0.0183\n",
      "Epoch 183/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9956 - loss: 0.0192 - val_accuracy: 0.9963 - val_loss: 0.0180\n",
      "Epoch 184/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9956 - loss: 0.0187 - val_accuracy: 0.9963 - val_loss: 0.0176\n",
      "Epoch 185/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9965 - loss: 0.0171 - val_accuracy: 0.9963 - val_loss: 0.0174\n",
      "Epoch 186/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9972 - loss: 0.0142 - val_accuracy: 0.9963 - val_loss: 0.0171\n",
      "Epoch 187/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9968 - loss: 0.0138 - val_accuracy: 0.9963 - val_loss: 0.0168\n",
      "Epoch 188/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9957 - loss: 0.0157 - val_accuracy: 0.9963 - val_loss: 0.0166\n",
      "Epoch 189/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9968 - loss: 0.0142 - val_accuracy: 0.9963 - val_loss: 0.0163\n",
      "Epoch 190/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9968 - loss: 0.0139 - val_accuracy: 0.9963 - val_loss: 0.0161\n",
      "Epoch 191/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9954 - loss: 0.0164 - val_accuracy: 0.9963 - val_loss: 0.0159\n",
      "Epoch 192/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9964 - loss: 0.0155 - val_accuracy: 0.9963 - val_loss: 0.0156\n",
      "Epoch 193/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9954 - loss: 0.0168 - val_accuracy: 0.9963 - val_loss: 0.0154\n",
      "Epoch 194/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9962 - loss: 0.0144 - val_accuracy: 0.9963 - val_loss: 0.0152\n",
      "Epoch 195/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9963 - val_loss: 0.0150\n",
      "Epoch 196/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9959 - loss: 0.0136 - val_accuracy: 0.9963 - val_loss: 0.0148\n",
      "Epoch 197/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9972 - loss: 0.0116 - val_accuracy: 0.9963 - val_loss: 0.0146\n",
      "Epoch 198/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9970 - loss: 0.0121 - val_accuracy: 0.9963 - val_loss: 0.0144\n",
      "Epoch 199/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9970 - loss: 0.0121 - val_accuracy: 0.9963 - val_loss: 0.0143\n",
      "Epoch 200/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.9963 - val_loss: 0.0141\n",
      "Epoch 201/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.9963 - val_loss: 0.0139\n",
      "Epoch 202/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9958 - loss: 0.0140 - val_accuracy: 0.9963 - val_loss: 0.0137\n",
      "Epoch 203/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.9963 - val_loss: 0.0136\n",
      "Epoch 204/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9969 - loss: 0.0114 - val_accuracy: 0.9963 - val_loss: 0.0134\n",
      "Epoch 205/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.9963 - val_loss: 0.0132\n",
      "Epoch 206/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9971 - loss: 0.0110 - val_accuracy: 0.9963 - val_loss: 0.0131\n",
      "Epoch 207/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9958 - loss: 0.0133 - val_accuracy: 0.9963 - val_loss: 0.0129\n",
      "Epoch 208/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9958 - loss: 0.0131 - val_accuracy: 0.9963 - val_loss: 0.0129\n",
      "Epoch 209/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.9963 - val_loss: 0.0127\n",
      "Epoch 210/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9963 - val_loss: 0.0125\n",
      "Epoch 211/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9963 - val_loss: 0.0124\n",
      "Epoch 212/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9982 - loss: 0.0088 - val_accuracy: 0.9963 - val_loss: 0.0123\n",
      "Epoch 213/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9963 - val_loss: 0.0121\n",
      "Epoch 214/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9966 - loss: 0.0106 - val_accuracy: 0.9963 - val_loss: 0.0120\n",
      "Epoch 215/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.9963 - val_loss: 0.0119\n",
      "Epoch 216/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9952 - loss: 0.0129 - val_accuracy: 0.9963 - val_loss: 0.0118\n",
      "Epoch 217/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9972 - loss: 0.0087 - val_accuracy: 0.9963 - val_loss: 0.0116\n",
      "Epoch 218/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.9963 - val_loss: 0.0115\n",
      "Epoch 219/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 0.9963 - val_loss: 0.0113\n",
      "Epoch 220/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9967 - loss: 0.0096 - val_accuracy: 0.9963 - val_loss: 0.0112\n",
      "Epoch 221/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9973 - loss: 0.0089 - val_accuracy: 0.9963 - val_loss: 0.0111\n",
      "Epoch 222/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9957 - loss: 0.0108 - val_accuracy: 0.9963 - val_loss: 0.0110\n",
      "Epoch 223/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9963 - loss: 0.0103 - val_accuracy: 0.9963 - val_loss: 0.0109\n",
      "Epoch 224/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9965 - loss: 0.0098 - val_accuracy: 0.9963 - val_loss: 0.0108\n",
      "Epoch 225/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9969 - loss: 0.0090 - val_accuracy: 0.9963 - val_loss: 0.0107\n",
      "Epoch 226/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9963 - val_loss: 0.0106\n",
      "Epoch 227/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9963 - val_loss: 0.0105\n",
      "Epoch 228/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9963 - val_loss: 0.0104\n",
      "Epoch 229/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.9963 - val_loss: 0.0103\n",
      "Epoch 230/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9946 - loss: 0.0114 - val_accuracy: 0.9963 - val_loss: 0.0103\n",
      "Epoch 231/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9963 - val_loss: 0.0101\n",
      "Epoch 232/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.9963 - val_loss: 0.0100\n",
      "Epoch 233/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 0.9963 - val_loss: 0.0099\n",
      "Epoch 234/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9956 - loss: 0.0095 - val_accuracy: 0.9963 - val_loss: 0.0098\n",
      "Epoch 235/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9968 - loss: 0.0082 - val_accuracy: 0.9963 - val_loss: 0.0097\n",
      "Epoch 236/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9961 - loss: 0.0098 - val_accuracy: 0.9963 - val_loss: 0.0096\n",
      "Epoch 237/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9961 - loss: 0.0093 - val_accuracy: 0.9963 - val_loss: 0.0095\n",
      "Epoch 238/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9945 - loss: 0.0101 - val_accuracy: 0.9963 - val_loss: 0.0095\n",
      "Epoch 239/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9971 - loss: 0.0074 - val_accuracy: 0.9963 - val_loss: 0.0094\n",
      "Epoch 240/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9963 - val_loss: 0.0093\n",
      "Epoch 241/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9963 - val_loss: 0.0093\n",
      "Epoch 242/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.9961 - loss: 0.0094 - val_accuracy: 0.9963 - val_loss: 0.0091\n",
      "Epoch 243/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9961 - loss: 0.0086 - val_accuracy: 0.9963 - val_loss: 0.0090\n",
      "Epoch 244/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9964 - loss: 0.0081 - val_accuracy: 0.9963 - val_loss: 0.0090\n",
      "Epoch 245/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9962 - loss: 0.0081 - val_accuracy: 0.9963 - val_loss: 0.0089\n",
      "Epoch 246/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9975 - loss: 0.0069 - val_accuracy: 0.9963 - val_loss: 0.0089\n",
      "Epoch 247/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.9963 - val_loss: 0.0087\n",
      "Epoch 248/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9968 - loss: 0.0084 - val_accuracy: 0.9963 - val_loss: 0.0086\n",
      "Epoch 249/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9959 - loss: 0.0085 - val_accuracy: 0.9963 - val_loss: 0.0086\n",
      "Epoch 250/250\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9965 - loss: 0.0072 - val_accuracy: 0.9963 - val_loss: 0.0085\n",
      "Filter shape: (5, 4, 1)\n",
      "Filter weights:\n",
      " [[ 1.7722211  -2.4017189  -2.4087021  -2.4111834 ]\n",
      " [ 0.10552536 -0.777137   -3.920156   -3.804135  ]\n",
      " [-2.7484066   1.200288   -2.7268705  -2.9175344 ]\n",
      " [-3.03794     1.1457185  -3.0123014  -3.0135858 ]\n",
      " [-1.4251202   0.8449769  -1.4463527  -1.3785866 ]]\n",
      "Filter bias:\n",
      " [-0.9092973]\n"
     ]
    }
   ],
   "source": [
    "model_single = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=1, kernel_size=5, activation='relu', input_shape=(15,4)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_single.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_single.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=250, batch_size=64)\n",
    "\n",
    "conv_layer = model_single.layers[0]\n",
    "filters, biases = conv_layer.get_weights()\n",
    "\n",
    "print(\"Filter shape:\", filters.shape)  \n",
    "print(\"Filter weights:\\n\", filters[..., 0])\n",
    "print(\"Filter bias:\\n\", biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = filters[..., 0]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(data, cmap='gray', aspect='auto')\n",
    "plt.colorbar(label='Value')\n",
    "plt.title(\"Grayscale Heatmap\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Rows\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.3745 - val_accuracy: 0.9930 - val_loss: 0.0316\n",
      "Epoch 2/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0275 - val_accuracy: 0.9827 - val_loss: 0.0432\n",
      "Epoch 3/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0111 - val_accuracy: 0.9970 - val_loss: 0.0120\n",
      "Epoch 4/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.9953 - val_loss: 0.0180\n",
      "Epoch 5/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0057 - val_accuracy: 0.9967 - val_loss: 0.0115\n",
      "Epoch 6/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9970 - val_loss: 0.0160\n",
      "Epoch 7/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9973 - val_loss: 0.0128\n",
      "Epoch 8/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 6.2968e-04 - val_accuracy: 0.9970 - val_loss: 0.0200\n",
      "Epoch 9/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0031 - val_accuracy: 0.9940 - val_loss: 0.0263\n",
      "Epoch 10/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0125 - val_accuracy: 0.9970 - val_loss: 0.0122\n",
      "Epoch 11/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9977 - val_loss: 0.0135\n",
      "Epoch 12/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 3.8996e-04 - val_accuracy: 0.9960 - val_loss: 0.0142\n",
      "Epoch 13/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 9.9255e-04 - val_accuracy: 0.9977 - val_loss: 0.0165\n",
      "Epoch 14/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.3181e-04 - val_accuracy: 0.9973 - val_loss: 0.0148\n",
      "Epoch 15/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.3350e-05 - val_accuracy: 0.9973 - val_loss: 0.0164\n",
      "Epoch 16/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.5463e-05 - val_accuracy: 0.9973 - val_loss: 0.0167\n",
      "Epoch 17/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0169e-05 - val_accuracy: 0.9973 - val_loss: 0.0172\n",
      "Epoch 18/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.4823e-05 - val_accuracy: 0.9973 - val_loss: 0.0175\n",
      "Epoch 19/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7442e-05 - val_accuracy: 0.9973 - val_loss: 0.0180\n",
      "Epoch 20/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0283e-05 - val_accuracy: 0.9973 - val_loss: 0.0180\n",
      "Epoch 21/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.6728e-05 - val_accuracy: 0.9973 - val_loss: 0.0177\n",
      "Epoch 22/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6217e-05 - val_accuracy: 0.9973 - val_loss: 0.0181\n",
      "Epoch 23/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.5587e-05 - val_accuracy: 0.9973 - val_loss: 0.0184\n",
      "Epoch 24/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.1338e-05 - val_accuracy: 0.9973 - val_loss: 0.0185\n",
      "Epoch 25/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.3169e-05 - val_accuracy: 0.9973 - val_loss: 0.0189\n",
      "Epoch 26/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.0182e-05 - val_accuracy: 0.9973 - val_loss: 0.0195\n",
      "Epoch 27/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.5626e-06 - val_accuracy: 0.9973 - val_loss: 0.0199\n",
      "Epoch 28/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8512e-06 - val_accuracy: 0.9973 - val_loss: 0.0194\n",
      "Epoch 29/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8166e-06 - val_accuracy: 0.9973 - val_loss: 0.0199\n",
      "Epoch 30/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.0581e-06 - val_accuracy: 0.9973 - val_loss: 0.0203\n",
      "Epoch 31/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.3916e-06 - val_accuracy: 0.9973 - val_loss: 0.0206\n",
      "Epoch 32/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.4862e-06 - val_accuracy: 0.9973 - val_loss: 0.0206\n",
      "Epoch 33/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.5352e-06 - val_accuracy: 0.9973 - val_loss: 0.0209\n",
      "Epoch 34/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1132e-06 - val_accuracy: 0.9973 - val_loss: 0.0209\n",
      "Epoch 35/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8316e-06 - val_accuracy: 0.9973 - val_loss: 0.0213\n",
      "Epoch 36/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.5125e-06 - val_accuracy: 0.9973 - val_loss: 0.0212\n",
      "Epoch 37/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6829e-06 - val_accuracy: 0.9973 - val_loss: 0.0214\n",
      "Epoch 38/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4512e-06 - val_accuracy: 0.9973 - val_loss: 0.0219\n",
      "Epoch 39/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.9700e-06 - val_accuracy: 0.9973 - val_loss: 0.0223\n",
      "Epoch 40/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.4524e-06 - val_accuracy: 0.9973 - val_loss: 0.0219\n",
      "Epoch 41/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.5182e-06 - val_accuracy: 0.9973 - val_loss: 0.0221\n",
      "Epoch 42/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.2235e-06 - val_accuracy: 0.9973 - val_loss: 0.0226\n",
      "Epoch 43/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.2075e-06 - val_accuracy: 0.9973 - val_loss: 0.0224\n",
      "Epoch 44/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4256e-06 - val_accuracy: 0.9973 - val_loss: 0.0229\n",
      "Epoch 45/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.2331e-06 - val_accuracy: 0.9973 - val_loss: 0.0226\n",
      "Epoch 46/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.1638e-06 - val_accuracy: 0.9973 - val_loss: 0.0238\n",
      "Epoch 47/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.7722e-06 - val_accuracy: 0.9973 - val_loss: 0.0231\n",
      "Epoch 48/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3589e-06 - val_accuracy: 0.9973 - val_loss: 0.0232\n",
      "Epoch 49/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.7348e-06 - val_accuracy: 0.9973 - val_loss: 0.0233\n",
      "Epoch 50/50\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4966e-06 - val_accuracy: 0.9973 - val_loss: 0.0240\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Single-filter CNN -> Loss: 0.00851062685251236  Accuracy: 0.9963333606719971\n",
      "Complex CNN       -> Loss: 0.023953603580594063  Accuracy: 0.9973333477973938\n"
     ]
    }
   ],
   "source": [
    "model_complex = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(15,4)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=512, kernel_size=4, activation='relu'),\n",
    "\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_complex.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_complex.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)\n",
    "\n",
    "loss_single, acc_single = model_single.evaluate(X_test, y_test, verbose=0)\n",
    "loss_complex, acc_complex = model_complex.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('\\n\\n\\n\\n\\n\\n\\n')\n",
    "print(\"Single-filter CNN -> Loss:\", loss_single, \" Accuracy:\", acc_single)\n",
    "print(\"Complex CNN       -> Loss:\", loss_complex, \" Accuracy:\", acc_complex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
